{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Luther\n",
    "## Dark Web Market Price Prediction\n",
    "\n",
    "#### by Skip Everling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook is three notebooks merged to include all code used for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import urllib.parse as urlparse\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to save and load a Python object as a JSON file\n",
    "import json\n",
    "def save_obj(data, name):\n",
    "    with open(name + '.json', 'w') as fp:\n",
    "        json.dump(data, fp, sort_keys=True, indent=4)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.json', 'r') as fp:\n",
    "        return json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to help extract quantity information from product title strings \n",
    "\n",
    "def get_quantity(prod_string):\n",
    "    '''Extracts the item quantity from product string'''\n",
    "    gram_pattern = \"[.\\d]+[ ]?[Gg]\"\n",
    "    kg_pattern = \"[.\\d]+[ ]?[Kk]\"\n",
    "    \n",
    "    gram_match = re.search(gram_pattern, prod_string)\n",
    "    if gram_match is None:\n",
    "        kg_match = re.search(kg_pattern, prod_string) # if no grams match, check if it's kilos or kg\n",
    "        if kg_match is None:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return raw_to_num_quant(kg_match.group())*1000\n",
    "    else:\n",
    "        return raw_to_num_quant(gram_match.group())\n",
    "\n",
    "def get_perc(prod_string):\n",
    "    '''Extracts the percentage quality from product string'''\n",
    "    perc_pattern = \"[.\\d]+[ ]?%\"\n",
    "    match = re.search(perc_pattern, prod_string)\n",
    "    if match is None:\n",
    "        return np.nan\n",
    "    else: \n",
    "        return float(match.group().replace(\"%\",\"\"))\n",
    "    \n",
    "\n",
    "def raw_to_num_quant(raw_quantity):\n",
    "    '''\n",
    "    Extracts the numeric value from the quantity string\n",
    "    e.g. \"14.0\" from \"14g\"\n",
    "    '''\n",
    "    if type(raw_quantity) is not str:\n",
    "        return np.nan\n",
    "    \n",
    "    pattern = \"(?:\\d*\\.)?\\d+\"\n",
    "    match = re.match(pattern, raw_quantity)\n",
    "    if match is None:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from forex_python.bitcoin import BtcConverter\n",
    "def btc_to_usd(btc_val):\n",
    "    return BtcConverter().get_latest_price('USD') * btc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tor (Anonymous Browsing and access to \"Dark Web\" pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this code sets web proxy to use Tor at port 9050\n",
    "# ip address inside this code should be different from public ip of the running computer\n",
    "import socks\n",
    "import socket\n",
    "import requests\n",
    "\n",
    "# changes default\n",
    "#socks.setdefaultproxy(proxy_type=socks.PROXY_TYPE_SOCKS5, addr=\"127.0.0.1\", port=9050)\n",
    "#socket.socket = socks.socksocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(requests.get(\"http://lchudifyeqm4ldjj.onion/?ai=1675\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "session = requests.session()\n",
    "# Tor uses the 9050 port as the default socks port\n",
    "# make sure tor is running\n",
    "session.proxies = {'http':  'socks5h://127.0.0.1:9050',\n",
    "                   'https': 'socks5h://127.0.0.1:9050'}\n",
    "\n",
    "# Make a request through the Tor connection\n",
    "# IP visible through Tor\n",
    "print(session.get(\"http://httpbin.org/ip\").text)\n",
    "# Above should print an IP different than your public IP\n",
    "\n",
    "# Following prints your normal public IP\n",
    "print(requests.get(\"http://httpbin.org/ip\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dream Market url: http://lchudifyeqm4ldjj.onion/?ai=1675\n",
    "# Dream Market username: lutherlooker\n",
    "# Dream Market password: lutherlookersee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.get(\"http://lchudifyeqm4ldjj.onion/?ai=1675\").text #Dream Market url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# above code is not necessary to run Selenium below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selenium to navigate sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to make Selenium work with Tor browser\n",
    "# must open TBB (Tor Browser Bundle) before running this, so that you establish a Tor circuit\n",
    "\n",
    "import os\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "from selenium import webdriver\n",
    "\n",
    "# path to the firefox binary inside the Tor package\n",
    "binary = '/Applications/TorBrowser.app/Contents/MacOS/firefox'\n",
    "if os.path.exists(binary) is False:\n",
    "    raise ValueError(\"The binary path to Tor firefox does not exist.\")\n",
    "firefox_binary = FirefoxBinary(binary)\n",
    "\n",
    "browser = None\n",
    "def get_browser(binary=None):\n",
    "    global browser  \n",
    "    # only one instance of a browser opens, remove global for multiple instances\n",
    "    if not browser: \n",
    "        browser = webdriver.Firefox(firefox_binary=binary)\n",
    "    return browser\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    browser = get_browser(binary=firefox_binary)\n",
    "    urls = (\n",
    "        ('tor browser check', 'https://check.torproject.org/'),\n",
    "        ('ip checker', 'http://icanhazip.com')\n",
    "    )\n",
    "    for url_name, url in urls:\n",
    "        print(\"getting\", url_name, \"at\", url)\n",
    "        browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#browser.get(\"https://check.torproject.com\")\n",
    "browser.get(\"http://lchudifyeqm4ldjj.onion/?ai=1675\") # Navigate to Dream Market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ...log in with user credentials manually (to get past bot-detection captcha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# After log in, go to Cocaine listings\n",
    "browser.get(\"http://lchudifyeqm4ldjj.onion/?category=187\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optionally get two big Javascript variables on the page that contain data about vendors and listings displayed\n",
    "#vendor_data = browser.execute_script(\"return proddata;\")\n",
    "#proddata = browser.execute_script(\"return proddata;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def make_listings_dict(html_doc):\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "    #find div tags that surround each displayed listing in results page\n",
    "    listings = soup.find_all(\"div\", class_=\"around\")\n",
    "\n",
    "    listings_dict = {}\n",
    "\n",
    "    for listing in listings:\n",
    "\n",
    "        title = listing.find(\"div\", class_=\"text oTitle\")\n",
    "        title_text = title.find(\"a\").get_text().strip()\n",
    "\n",
    "        domain = \"http://jd6yhuwcivehvdt4.onion\"\n",
    "        product_link= title.a[\"href\"][1:] # get relative path link\n",
    "        product_link = domain + product_link # turn into absolute path link\n",
    "\n",
    "        body = listing.find(\"div\", class_=\"oOfferBody\")\n",
    "\n",
    "        escrow_tag = body.find(\"div\", class_=\"escrowInfo\")\n",
    "        escrow = escrow_tag.find(\"div\").get_text()\n",
    "        \n",
    "        btc_price = body.find(\"div\", class_=\"bottom oPrice\").get_text().strip()\n",
    "\n",
    "        vendor = body.find(\"div\", class_=\"oVendor\")\n",
    "        vendor_tag = vendor.find(\"a\")\n",
    "        vendor_name = vendor.find(\"a\").get_text().strip() # first a tag in vendor div tag is vendor's name\n",
    "        vendor_link = domain + vendor_tag[\"href\"][1:]\n",
    "\n",
    "        transactions = body.find(\"span\", title=\"Successful transactions\").get_text().replace(\"(\",\"\").replace(\")\",\"\")\n",
    "\n",
    "        rating = body.find(\"span\", class_=\"userRating gold\").get_text().strip() if body.find(\"span\", class_=\"userRating gold\") else None \n",
    "\n",
    "        ships_from_to = body.find(\"span\", class_=\"osBod\").get_text().strip()\n",
    "\n",
    "        listings_dict[title_text] = {\n",
    "                                \"product_title\": title_text,\n",
    "                                \"product_link\" : product_link,\n",
    "                                \"escrow\"       : str(escrow),\n",
    "                                \"btc_price\"    : btc_price,\n",
    "                                \"vendor_name\"  : vendor_name,\n",
    "                                \"vendor_link\"  : vendor_link,\n",
    "                                \"successful_transactions\" : transactions,\n",
    "                                \"rating\" : rating,\n",
    "                                \"ships_from_to\" : ships_from_to\n",
    "                               }\n",
    "    \n",
    "    return listings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_page():\n",
    "    page = make_listings_dict(browser.page_source)\n",
    "    #print(type(page))\n",
    "    page_url = browser.current_url\n",
    "    #print(page_url)\n",
    "\n",
    "    parsed = urlparse.urlparse(page_url)\n",
    "    #print(urlparse.parse_qs(parsed.query))\n",
    "    page_num = urlparse.parse_qs(parsed.query)['page']\n",
    "\n",
    "    save_obj(page, \"page\"+ page_num[0])\n",
    "    print(\"Saved file: page\" + page_num[0] + \".json\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and click the \"Next Page\" button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def go_to_next_page():\n",
    "\n",
    "    ### Find the \"Next Page\" button\n",
    "    # format of HTML: <a class=\"gPager lastPager\" title=\"Next page\" href=...> </a>\n",
    "    next_page_button = browser.find_element_by_class_name(\"lastPager\")\n",
    "\n",
    "    ### Go to the page listed in href attribute of that HTML link element\n",
    "    # example: href=\"./?page=3\"\n",
    "    next_page = next_page_button.get_attribute(\"href\")\n",
    "    browser.get(next_page)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### browse and collect listings ###\n",
    "for i in range(1, 3000):\n",
    "    \n",
    "    try:\n",
    "        save_page()\n",
    "        go_to_next_page()\n",
    "        time.sleep(15 + (random.randint(0, 3000) / 1000)) # 15s plus 1-3s\n",
    "    except:\n",
    "        print(\"Error after {} pages.\".format(i))\n",
    "        break\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        time.sleep(10)\n",
    "        #browser.get(\"http://lchudifyeqm4ldjj.onion/?category=104\")\n",
    "        #browser.back()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect vendor pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of unique vendor_links\n",
    "vendor_links = list(cocaine_listings[\"vendor_link\"].unique())\n",
    "print(len(vendor_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# iterate through vendor links and collect vendor page data\n",
    "\n",
    "for link in vendor_links:\n",
    "    \n",
    "    parsed = urlparse.urlparse(link)\n",
    "    vendor_name = urlparse.parse_qs(parsed.query)['member'][0]\n",
    "    vendor_dict[vendor_name] = {}\n",
    "    \n",
    "    ratings_url = link + \"&tab=ratings#tabChooser\"\n",
    "    browser.get(ratings_url)\n",
    "    \n",
    "    time.sleep(5)\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    \n",
    "    ### Get some vendor info\n",
    "    member_since = soup.find(\"label\", text=\"Join date\")\n",
    "    vendor_dict[vendor_name][\"vendorJoinDate\"] = member_since.find_next(\"span\").get_text()\n",
    "\n",
    "    ##########\n",
    "    ### Scrape the vendor's ratings table\n",
    "    rating_table = soup.find(\"div\", id=\"tableOfRatings\")\n",
    "    \n",
    "    #1mo\n",
    "    newer_than_1mo = rating_table.find('td', text = re.compile('Newer than 1 Month'))\n",
    "    stars1 = newer_than_1mo.find_next('td')\n",
    "    stars2 = stars1.find_next('td')\n",
    "    stars3 = stars2.find_next('td')\n",
    "    stars4 = stars3.find_next('td')\n",
    "    stars5 = stars4.find_next('td')\n",
    "    \n",
    "    vendor_dict[vendor_name][\"oneStars_1mo\"] = stars1.get_text()\n",
    "    vendor_dict[vendor_name][\"twoStars_1mo\"] = stars2.get_text()\n",
    "    vendor_dict[vendor_name][\"threeStars_1mo\"] = stars3.get_text()\n",
    "    vendor_dict[vendor_name][\"fourStars_1mo\"] = stars4.get_text()\n",
    "    vendor_dict[vendor_name][\"fiveStars_1mo\"] = stars5.get_text()\n",
    " \n",
    "    #3mos\n",
    "    newer_than_3mo = rating_table.find('td', text = re.compile('Newer than 3 Months'))\n",
    "    stars1 = newer_than_3mo.find_next('td')\n",
    "    stars2 = stars1.find_next('td')\n",
    "    stars3 = stars2.find_next('td')\n",
    "    stars4 = stars3.find_next('td')\n",
    "    stars5 = stars4.find_next('td')\n",
    "    \n",
    "    vendor_dict[vendor_name][\"oneStars_3mo\"] = stars1.get_text()\n",
    "    vendor_dict[vendor_name][\"twoStars_3mo\"] = stars2.get_text()\n",
    "    vendor_dict[vendor_name][\"threeStars_3mo\"] = stars3.get_text()\n",
    "    vendor_dict[vendor_name][\"fourStars_3mo\"] = stars4.get_text()\n",
    "    vendor_dict[vendor_name][\"fiveStars_3mo\"] = stars5.get_text()\n",
    "    \n",
    "    #3+mos\n",
    "    older_than_3mo = rating_table.find('td', text = re.compile('Older'))\n",
    "    stars1 = older_than_3mo.find_next('td')\n",
    "    stars2 = stars1.find_next('td')\n",
    "    stars3 = stars2.find_next('td')\n",
    "    stars4 = stars3.find_next('td')\n",
    "    stars5 = stars4.find_next('td')\n",
    "    \n",
    "    vendor_dict[vendor_name][\"oneStars_old3mos\"] = stars1.get_text()\n",
    "    vendor_dict[vendor_name][\"twoStars_old3mos\"] = stars2.get_text()\n",
    "    vendor_dict[vendor_name][\"threeStars_old3mos\"] = stars3.get_text()\n",
    "    vendor_dict[vendor_name][\"fourStars_old3mos\"] = stars4.get_text()\n",
    "    vendor_dict[vendor_name][\"fiveStars_old3mos\"] = stars5.get_text()\n",
    "    ########\n",
    "    \n",
    "    ###\n",
    "    # get order totals and sum them\n",
    "    total_paid_to_vendor = 0\n",
    "    buyers = soup.find(\"table\", class_=\"ratingTable hoverable\")\n",
    "    buyers_paid = buyers.find_all(\"td\", text = re.compile('~ ฿')) #find amount paid e.g.: ~ ฿0.02\n",
    "    for buyer_paid in buyers_paid:\n",
    "        buyer_paid = buyer_paid.get_text()\n",
    "        if \".\" in buyer_paid:\n",
    "            buyer_paid = float(\".\" + buyer_paid.split(\".\")[1])\n",
    "        else:\n",
    "            buyer_paid = float(buyer_paid.split(\"฿\")[1])\n",
    "        total_paid_to_vendor += buyer_paid\n",
    "        \n",
    "    vendor_dict[vendor_name][\"recent_order_sum_total\"] = total_paid_to_vendor\n",
    "    #pprint.pprint(vendor_dict)\n",
    "    print(\"Added info for {} to vendor dict.\".format(vendor_name))\n",
    "    \n",
    "    vendor_links.remove(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save collected vendor information as a JSON file\n",
    "save_obj(vendor_dict, \"cocaine_vendors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load collected vendor information from JSON file\n",
    "vendor_dict = load_obj(\"cocaine_vendors\")\n",
    "vendor_df = pd.DataFrame(vendor_dict).transpose()\n",
    "vendor_df.reset_index(inplace=True)\n",
    "vendor_df.rename(columns={\"index\":\"vendor_name\"}, inplace=True)\n",
    "\n",
    "# Fix some data types in dataframe since they were collected as generic objects in original dict \n",
    "vendor_df['vendorJoinDate'] = pd.to_datetime(vendor_df['vendorJoinDate'])\n",
    "vendor_df['recent_order_sum_total'] = pd.to_numeric(vendor_df['recent_order_sum_total'])\n",
    "for column in vendor_df.columns:\n",
    "    if \"Stars\" in column:\n",
    "        vendor_df[column] = pd.to_numeric(vendor_df[column])\n",
    "\n",
    "vendor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import urllib.parse as urlparse\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import ml_insights as mli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to save and load a Python object as a JSON file\n",
    "import json\n",
    "def save_obj(data, name):\n",
    "    with open(name + '.json', 'w') as fp:\n",
    "        json.dump(data, fp, sort_keys=True, indent=4)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.json', 'r') as fp:\n",
    "        return json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to help extract quantity information from product title strings \n",
    "\n",
    "def get_quantity(prod_string):\n",
    "    '''Extracts the item quantity from product string'''\n",
    "    gram_pattern = \"[.\\d]+[ ]?[Gg]\"\n",
    "    kg_pattern = \"[.\\d]+[ ]?[Kk]\"\n",
    "    \n",
    "    gram_match = re.search(gram_pattern, prod_string)\n",
    "    if gram_match is None:\n",
    "        kg_match = re.search(kg_pattern, prod_string) # if no grams match, check if it's kilos or kg\n",
    "        if kg_match is None:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return raw_to_num_quant(kg_match.group())*1000\n",
    "    else:\n",
    "        return raw_to_num_quant(gram_match.group())\n",
    "\n",
    "def get_perc(prod_string):\n",
    "    '''Extracts the percentage quality from product string'''\n",
    "    perc_pattern = \"[.\\d]+[ ]?%\"\n",
    "    match = re.search(perc_pattern, prod_string)\n",
    "    if match is None:\n",
    "        return np.nan\n",
    "    else: \n",
    "        return float(match.group().replace(\"%\",\"\"))\n",
    "    \n",
    "\n",
    "def raw_to_num_quant(raw_quantity):\n",
    "    '''\n",
    "    Extracts the numeric value from the quantity string\n",
    "    e.g. \"14.0\" from \"14g\"\n",
    "    '''\n",
    "    if type(raw_quantity) is not str:\n",
    "        return np.nan\n",
    "    \n",
    "    pattern = \"(?:\\d*\\.)?\\d+\"\n",
    "    match = re.match(pattern, raw_quantity)\n",
    "    if match is None:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from forex_python.bitcoin import BtcConverter\n",
    "def btc_to_usd(btc_val):\n",
    "    return BtcConverter().get_latest_price('USD') * btc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load and combine the saved JSON files for cocaine\n",
    "folder = \"/Users/davideverling/metis/sf17_ds7/student_submissions/projects/02-luther/skip/cocaine_jul-14\"\n",
    "\n",
    "listings_dict = {}\n",
    "for i in range(1, 170):\n",
    "    page_dict = load_obj(folder + \"/page\" + str(i))\n",
    "    listings_dict.update(page_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform loaded dict into a Pandas dataframe\n",
    "cocaine_listings = pd.DataFrame(listings_dict).transpose()\n",
    "cocaine_listings.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Process the data ######\n",
    "\n",
    "### get quantity and quality from product title strings ###\n",
    "\n",
    "cocaine_listings[\"grams\"] = cocaine_listings[\"product_title\"].apply(get_quantity)\n",
    "cocaine_listings[\"quality\"] = cocaine_listings[\"product_title\"].apply(get_perc)\n",
    "cocaine_listings[\"quality\"][cocaine_listings[\"quality\"] < 50] = np.nan # get rid of unusually low quality ratings\n",
    "cocaine_listings[\"quality\"].fillna(cocaine_listings[\"quality\"].mean()) #set a default quality of the average quality\n",
    "\n",
    "### clean up Bitcoin prices -- remove btc symbol and convert to float\n",
    "cocaine_listings[\"btc_price\"] = cocaine_listings[\"btc_price\"].map(lambda x: float(x[1:]))\n",
    "cocaine_listings[\"cost_per_gram\"] = cocaine_listings[\"btc_price\"] / cocaine_listings[\"grams\"]\n",
    "cocaine_listings[\"cost_per_gram\"].dropna(inplace=True)\n",
    "cocaine_listings[\"cost_per_gram_pure\"] = cocaine_listings[\"cost_per_gram\"] * 1/(cocaine_listings['quality']/100)\n",
    "\n",
    "\n",
    "btc_2_usd_rate = btc_to_usd(1) # get price of 1 bitcoin\n",
    "### uncomment line below to make a corresponding USD column for analysis\n",
    "#cocaine_listings[\"usd_price_at_rate_\"+str(btc_2_usd_rate)] = cocaine_listings[\"btc_price\"].map(lambda x: x*btc_2_usd_rate)\n",
    "\n",
    "### convert escrow string to a 1 or 0\n",
    "escrow_map = {\"NO ESCROW\":0, \"ESCROW\":1}\n",
    "cocaine_listings[\"escrow\"] = cocaine_listings[\"escrow\"].map(escrow_map)\n",
    "\n",
    "### get rid of rows that don't have values\n",
    "cocaine_listings.dropna(inplace=True)\n",
    "\n",
    "### convert ratings and successful_transactions to numbers\n",
    "cocaine_listings[\"rating\"] = cocaine_listings[\"rating\"].map(float)\n",
    "cocaine_listings[\"successful_transactions\"] = cocaine_listings[\"successful_transactions\"].map(int)\n",
    "\n",
    "\n",
    "### Ships FROM and TO ###\n",
    "\n",
    "# split ships-from and ships-to into separate columns\n",
    "cocaine_listings[\"ships_from\"] = cocaine_listings[\"ships_from_to\"].map(lambda x: x.split(\"\\u2192\")[0].strip())\n",
    "cocaine_listings[\"ships_to\"] = cocaine_listings[\"ships_from_to\"].map(lambda x: x.split(\"\\u2192\")[1].strip())\n",
    "\n",
    "# creates dummy variable columns with True/False whether the vendor ships to that country\n",
    "countries = ['US', 'NL', 'FR', 'GB', 'CA', 'DE', 'AU', 'EU', 'ES', 'N. America', 'BE', 'WW', 'SI',\n",
    " 'IT', 'DK', 'S. America', 'CH', 'BR', 'CZ', 'SE', 'CO', 'CN', 'PL', 'GR']\n",
    "for country in countries:\n",
    "    cocaine_listings['ships_to_'+ country] = cocaine_listings['ships_to'].str.contains(country) \n",
    "    cocaine_listings['ships_from_'+ country] = cocaine_listings['ships_from'].str.contains(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cocaine_listings.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cocaine_listings.to_excel(\"dream_market_cocaine_listings.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vendor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load collected vendor information from JSON file\n",
    "vendor_dict = load_obj(\"cocaine_vendors\")\n",
    "vendor_df = pd.DataFrame(vendor_dict).transpose()\n",
    "vendor_df.reset_index(inplace=True)\n",
    "vendor_df.rename(columns={\"index\":\"vendor_name\"}, inplace=True)\n",
    "\n",
    "# Fix some data types in dataframe since they were collected as generic objects in original dict \n",
    "vendor_df['vendorJoinDate'] = pd.to_datetime(vendor_df['vendorJoinDate'])\n",
    "vendor_df['recent_order_sum_total'] = pd.to_numeric(vendor_df['recent_order_sum_total'])\n",
    "for column in vendor_df.columns:\n",
    "    if \"Stars\" in column:\n",
    "        vendor_df[column] = pd.to_numeric(vendor_df[column])\n",
    "\n",
    "vendor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge vendor df with listings df\n",
    "merged_df = pd.merge(cocaine_listings, vendor_df, on='vendor_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.info(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis of Full Merged Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='ships_from', y='cost_per_gram', hue='ships_to_AU',data=merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of listings from each country\n",
    "sns.countplot(x='ships_from', data=model_df, hue='ships_to_US')\n",
    "plt.title(\"Listings by country of origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['cost_per_gram_pure']*btc_to_usd(1))\n",
    "plt.suptitle(\"Avg. Cost per gram of 100% pure cocaine\")\n",
    "plt.xlabel(\"Cost in USD\")\n",
    "plt.ylabel(\"Proportion of Listings\")\n",
    "plt.axvline((df['cost_per_gram_pure']*btc_to_usd(1)).median(), color='b', linestyle='dashed', linewidth=1)\n",
    "print(\"Median:\", np.median(df['cost_per_gram_pure']*btc_to_usd(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize vendors and their average price per gram\n",
    "by_vendor = merged_df.groupby(by='vendor_name').mean()\n",
    "by_vendor.reset_index(inplace=True)\n",
    "by_vendor.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(by_vendor['recent_order_sum_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(by_vendor['cost_per_gram_pure']*btc_to_usd(1))\n",
    "plt.suptitle(\"Disribution of rates in USD for 1 gram, by vendor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframes for machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of columns we won't use for machine learning models\n",
    "model_df = merged_df.drop(['index','product_title','product_link', 'ships_from_to', 'vendor_link', 'cost_per_gram', 'cost_per_gram_pure', 'recent_order_sum_total'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_df = model_df[[\"btc_price\",\"escrow\",\"rating\",\"successful_transactions\",\"grams\",\"quality\"]]\n",
    "#simple_df = model_df[[\"btc_price\",\"grams\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model,ensemble, tree, model_selection, cross_validation, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatter_matrix(X):\n",
    "    feature_count = len(X.columns)\n",
    "    fig,ax = plt.subplots(ncols=feature_count,nrows=feature_count,figsize=(10*feature_count, 10*feature_count))\n",
    "\n",
    "    for i,feature_i in enumerate(X):\n",
    "        for j,feature_j in enumerate(X):\n",
    "            ax[i][j].scatter(X[feature_i],X[feature_j])\n",
    "            ax[i][j].set_xlabel('Feature ' + str(feature_j))\n",
    "            ax[i][j].set_ylabel('Feature ' + str(feature_i))\n",
    "\n",
    "scatter_matrix(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Prediction  -- Linear Regression to predict btc_price with quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_df[[\"btc_price\",\"grams\"]]\n",
    "#df = by_vendor.drop('vendor_name', axis=1)\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "#set predictors and target\n",
    "X = df.drop('btc_price', axis=1)\n",
    "y = df['btc_price']\n",
    "\n",
    "#make splits for training and testing\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,train_size=.7)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "scores = model_selection.cross_val_score(model, X_train, y_train, n_jobs=1)\n",
    "score = np.mean(scores)\n",
    "\n",
    "print(\"RMSE\", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"Score: \", score)\n",
    "print(\"Intercept: \", model.intercept_)\n",
    "#print(\"Coeff: \", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "plt.xlabel('Measured')\n",
    "plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond Linear Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#choose dataframe to operate on\n",
    "df = model_df.drop(['vendorJoinDate','ships_to', 'ships_from', 'vendor_name'], axis=1)\n",
    "#df = model_df[[\"btc_price\",\"escrow\",\"rating\",\"successful_transactions\",\"grams\",\"quality\"]]\n",
    "#df = by_vendor.drop('vendor_name', axis=1)\n",
    "\n",
    "#set predictors and target\n",
    "X = df.drop('btc_price', axis=1) #predict with every column in df except btc_price\n",
    "y = df['btc_price']\n",
    "\n",
    "#make splits for training and testing\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,train_size=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "parameters = {}\n",
    "\n",
    "parameters['normalize'] = False\n",
    "\n",
    "models['linear_model'] = linear_model.LinearRegression()\n",
    "models['ridge_model'] = linear_model.Ridge()\n",
    "models['lasso_model'] = linear_model.Lasso(alpha=.5)\n",
    "models['robust_regression'] = linear_model.SGDRegressor(loss='huber',n_iter=20)\n",
    "models['eps_insensitive'] = linear_model.SGDRegressor(loss='epsilon_insensitive',n_iter=20)\n",
    "\n",
    "\n",
    "models['cart'] = tree.DecisionTreeRegressor(max_depth=7)\n",
    "models['extratrees'] = tree.ExtraTreeRegressor(max_depth=7)\n",
    "models['randomForest'] = ensemble.RandomForestRegressor()\n",
    "models['adaboostedTrees'] = ensemble.AdaBoostRegressor()\n",
    "models['gradboostedTrees'] = ensemble.GradientBoostingRegressor(learning_rate=0.05, n_estimators=1000)\n",
    "\n",
    "\n",
    "for name,model in models.items():\n",
    "    scores = model_selection.cross_val_score(model, X_train, y_train, n_jobs=1)\n",
    "    print('Model: '+ name)\n",
    "    print(\"Score: \" + str(np.mean(scores)))\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"RMSE\", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    #print(\"Prediction for 1 gram:\", model.predict([1.0])*btc_2_usd_rate)\n",
    "    \n",
    "    test_point = X_test.sample(1)\n",
    "    test_point[\"grams\"] = 1000\n",
    "    test_point[\"quality\"] = 90.0\n",
    "    #print(test_point)\n",
    "    print(\"Test point:\", model.predict(test_point)*btc_to_usd(1))\n",
    "    print()\n",
    "    \n",
    "    if model == models['gradboostedTrees']:\n",
    "        plt.scatter(y_test, y_pred)\n",
    "        plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "        plt.xlabel('Measured')\n",
    "        plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Test different alphas for Lasso\n",
    "# alpha_vec = np.logspace(-3,3,7)\n",
    "# #print(alpha_vec)\n",
    "\n",
    "# for alpha in alpha_vec:\n",
    "#     model = linear_model.Lasso(alpha=alpha)\n",
    "\n",
    "#     scores = model_selection.cross_val_score(model, X_train, y_train, n_jobs=1)\n",
    "#     #print('Model: '+ str(model))\n",
    "#     score = str(np.mean(scores))\n",
    "#     #print(\"Score: \" + score)\n",
    "#     model.fit(X_train,y_train)\n",
    "#     print(alpha, score)\n",
    "\n",
    "    \n",
    "# coef_df = pd.DataFrame(list(zip(X.columns,model.coef_)))\n",
    "# coef_df = coef_df[coef_df[1] != 0]\n",
    "# coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Alpha around 0.5 to 1.0 works best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso selects the following features: grams, fiveStars_1mo, fiveStars_3mo, fiveStars_old3mos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs = models['lasso_model'].fit(X,y).coef_\n",
    "sorted(zip(X.columns,coefs), key = lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_overfit(X,y,model_obj,param_ranges,param_static=None): \n",
    "    for parameter,parameter_range in param_ranges.items():\n",
    "        avg_train_score, avg_test_score = [],[]\n",
    "        std_train_score, std_test_score = [],[]\n",
    "        \n",
    "        for param_val in parameter_range:\n",
    "            param = {parameter:param_val}\n",
    "            if param_static:\n",
    "                param.update(param_static)\n",
    "            \n",
    "                \n",
    "            model = model_obj(**param)\n",
    "            \n",
    "            train_scores,test_scores = [],[]\n",
    "            for i in range(5):\n",
    "                X_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,test_size = .3)\n",
    "                model.fit(X_train,y_train)\n",
    "                \n",
    "                train_scores.append(model.score(X_train,y_train))\n",
    "                test_scores.append(model.score(X_test,y_test))\n",
    "            \n",
    "            avg_train_score.append(np.mean(train_scores))\n",
    "            avg_test_score.append(np.mean(test_scores))\n",
    "            \n",
    "            std_train_score.append(np.std(train_scores))\n",
    "            std_test_score.append(np.std(test_scores))\n",
    "            \n",
    "        fig,ax = plt.subplots()\n",
    "        ax.errorbar(parameter_range,avg_train_score,yerr=std_train_score,label='training score')\n",
    "        ax.errorbar(parameter_range,avg_test_score,yerr=std_test_score,label='testing score')\n",
    "        \n",
    "        ax.set_xlabel(parameter)\n",
    "        ax.set_ylabel('score')\n",
    "        ax.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_obj = ensemble.RandomForestRegressor\n",
    "#model_obj = linear_model.Lasso\n",
    "param_ranges = {'alpha':np.logspace(-3,3,7)}\n",
    "\n",
    "plot_overfit(X,y,model_obj,param_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models['gradboostedTrees']\n",
    "model.fit(X_train,y_train)\n",
    "mxr = mli.ModelXRay(model, X_test);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = mxr.feature_dependence_plots(num_pts=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mxr.feature_effect_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Luther\n",
    "\n",
    "#### by Skip Everling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import urllib.parse as urlparse\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to save and load a Python object as a JSON file\n",
    "import json\n",
    "def save_obj(data, name):\n",
    "    with open(name + '.json', 'w') as fp:\n",
    "        json.dump(data, fp, sort_keys=True, indent=4)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.json', 'r') as fp:\n",
    "        return json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tor (Anonymous Browsing and access to \"Dark Web\" pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this code sets web proxy to use Tor at port 9050\n",
    "# ip address inside this code should be different from public ip of the running computer\n",
    "import socks\n",
    "import socket\n",
    "import requests\n",
    "\n",
    "# changes default\n",
    "#socks.setdefaultproxy(proxy_type=socks.PROXY_TYPE_SOCKS5, addr=\"127.0.0.1\", port=9050)\n",
    "#socket.socket = socks.socksocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(requests.get(\"http://lchudifyeqm4ldjj.onion/?ai=1675\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "session = requests.session()\n",
    "# Tor uses the 9050 port as the default socks port\n",
    "# make sure tor is running\n",
    "session.proxies = {'http':  'socks5h://127.0.0.1:9050',\n",
    "                   'https': 'socks5h://127.0.0.1:9050'}\n",
    "\n",
    "# Make a request through the Tor connection\n",
    "# IP visible through Tor\n",
    "print(session.get(\"http://httpbin.org/ip\").text)\n",
    "# Above should print an IP different than your public IP\n",
    "\n",
    "# Following prints your normal public IP\n",
    "print(requests.get(\"http://httpbin.org/ip\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dream Market url: http://lchudifyeqm4ldjj.onion/?ai=1675\n",
    "# Dream Market username: lutherlooker\n",
    "# Dream Market password: lutherlookersee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.get(\"http://lchudifyeqm4ldjj.onion/?ai=1675\").text #Dream Market url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each listing collected, go to product listing page and get Product Description and Product-specific Reviews\n",
    "\n",
    "# for each vendor in vendor list, go to their vendor page and get stats\n",
    "# e.g. http://lchudifyeqm4ldjj.onion/contactMember?member=vendor_name\n",
    "\n",
    "\n",
    "# go to Ratings tab and get Ratings distribution table as additional predictors\n",
    "\n",
    "# get avg order value from 50 most recent reviewers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# above code is not necessary to run Selenium below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selenium to navigate sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to make Selenium work with Tor browser\n",
    "# must open TBB (Tor Browser Bundle) before running this, so that you establish a Tor circuit\n",
    "\n",
    "import os\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "from selenium import webdriver\n",
    "\n",
    "# path to the firefox binary inside the Tor package\n",
    "binary = '/Applications/TorBrowser.app/Contents/MacOS/firefox'\n",
    "if os.path.exists(binary) is False:\n",
    "    raise ValueError(\"The binary path to Tor firefox does not exist.\")\n",
    "firefox_binary = FirefoxBinary(binary)\n",
    "\n",
    "browser = None\n",
    "def get_browser(binary=None):\n",
    "    global browser  \n",
    "    # only one instance of a browser opens, remove global for multiple instances\n",
    "    if not browser: \n",
    "        browser = webdriver.Firefox(firefox_binary=binary)\n",
    "    return browser\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    browser = get_browser(binary=firefox_binary)\n",
    "    urls = (\n",
    "        ('tor browser check', 'https://check.torproject.org/'),\n",
    "        ('ip checker', 'http://icanhazip.com')\n",
    "    )\n",
    "    for url_name, url in urls:\n",
    "        print(\"getting\", url_name, \"at\", url)\n",
    "        browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#browser.get(\"https://check.torproject.com\")\n",
    "browser.get(\"http://lchudifyeqm4ldjj.onion/?ai=1675\") # Navigate to Dream Market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ...log in with user credentials manually (to get past bot-detection captcha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After log in, go to Cocaine listings\n",
    "browser.get(\"http://lchudifyeqm4ldjj.onion/?category=187\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get two big Javascript variables on the page that contain data about vendors and listings displayed\n",
    "#vendor_data = browser.execute_script(\"return proddata;\")\n",
    "#proddata = browser.execute_script(\"return proddata;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def make_listings_dict(html_doc):\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "    #find div tags that surround each displayed listing in results page\n",
    "    listings = soup.find_all(\"div\", class_=\"around\")\n",
    "\n",
    "    listings_dict = {}\n",
    "\n",
    "    for listing in listings:\n",
    "\n",
    "        title = listing.find(\"div\", class_=\"text oTitle\")\n",
    "        title_text = title.find(\"a\").get_text().strip()\n",
    "\n",
    "        domain = \"http://jd6yhuwcivehvdt4.onion\"\n",
    "        product_link= title.a[\"href\"][1:] # get relative path link\n",
    "        product_link = domain + product_link # turn into absolute path link\n",
    "\n",
    "        body = listing.find(\"div\", class_=\"oOfferBody\")\n",
    "\n",
    "        escrow_tag = body.find(\"div\", class_=\"escrowInfo\")\n",
    "        escrow = escrow_tag.find(\"div\").get_text()\n",
    "        \n",
    "        btc_price = body.find(\"div\", class_=\"bottom oPrice\").get_text().strip()\n",
    "\n",
    "        vendor = body.find(\"div\", class_=\"oVendor\")\n",
    "        vendor_tag = vendor.find(\"a\")\n",
    "        vendor_name = vendor.find(\"a\").get_text().strip() # first a tag in vendor div tag is vendor's name\n",
    "        vendor_link = domain + vendor_tag[\"href\"][1:]\n",
    "\n",
    "        transactions = body.find(\"span\", title=\"Successful transactions\").get_text().replace(\"(\",\"\").replace(\")\",\"\")\n",
    "\n",
    "        rating = body.find(\"span\", class_=\"userRating gold\").get_text().strip() if body.find(\"span\", class_=\"userRating gold\") else None \n",
    "\n",
    "        ships_from_to = body.find(\"span\", class_=\"osBod\").get_text().strip()\n",
    "\n",
    "        listings_dict[title_text] = {\n",
    "                                \"product_title\": title_text,\n",
    "                                \"product_link\" : product_link,\n",
    "                                \"escrow\"       : str(escrow),\n",
    "                                \"btc_price\"    : btc_price,\n",
    "                                \"vendor_name\"  : vendor_name,\n",
    "                                \"vendor_link\"  : vendor_link,\n",
    "                                \"successful_transactions\" : transactions,\n",
    "                                \"rating\" : rating,\n",
    "                                \"ships_from_to\" : ships_from_to\n",
    "                               }\n",
    "    \n",
    "    return listings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_page():\n",
    "    page = make_listings_dict(browser.page_source)\n",
    "    #print(type(page))\n",
    "    page_url = browser.current_url\n",
    "    #print(page_url)\n",
    "\n",
    "    parsed = urlparse.urlparse(page_url)\n",
    "    #print(urlparse.parse_qs(parsed.query))\n",
    "    page_num = urlparse.parse_qs(parsed.query)['page']\n",
    "\n",
    "    save_obj(page, \"page\"+ page_num[0])\n",
    "    print(\"Saved file: page\" + page_num[0] + \".json\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and click the \"Next Page\" button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def go_to_next_page():\n",
    "\n",
    "    ### Find the \"Next Page\" button\n",
    "    # format of HTML: <a class=\"gPager lastPager\" title=\"Next page\" href=...> </a>\n",
    "    next_page_button = browser.find_element_by_class_name(\"lastPager\")\n",
    "\n",
    "    ### Go to the page listed in href attribute of that HTML link element\n",
    "    # example: href=\"./?page=3\"\n",
    "    next_page = next_page_button.get_attribute(\"href\")\n",
    "    browser.get(next_page)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### browse and collect listings ###\n",
    "for i in range(1, 3000):\n",
    "    \n",
    "    try:\n",
    "        save_page()\n",
    "        go_to_next_page()\n",
    "        time.sleep(15 + (random.randint(0, 3000) / 1000)) # 15s plus 1-3s\n",
    "    except:\n",
    "        print(\"Error after {} pages.\".format(i))\n",
    "        break\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        time.sleep(10)\n",
    "        #browser.get(\"http://lchudifyeqm4ldjj.onion/?category=104\")\n",
    "        #browser.back()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
