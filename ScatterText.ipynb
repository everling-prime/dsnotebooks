{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T01:50:47.444760Z",
     "start_time": "2017-08-25T01:50:46.977306Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "%config Application.log_level=\"INFO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T01:54:38.840499Z",
     "start_time": "2017-08-25T01:54:38.820844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 50000\n",
      "Old Major, the old boar on the Manor Farm, summons the animals on the farm together for a meeting, d\n"
     ]
    }
   ],
   "source": [
    "## Read in data\n",
    "\n",
    "sample_size = 50000\n",
    "\n",
    "### Select first items up to sample_size\n",
    "if not sample_size:\n",
    "    sample_size = len(raw_plots)\n",
    "\n",
    "print(\"Sample size:\", sample_size)\n",
    "\n",
    "%store -r raw_titles\n",
    "%store -r raw_plots\n",
    "\n",
    "plot_dict = dict(zip(raw_titles[:sample_size], raw_plots[:sample_size]))\n",
    "print(plot_dict[\"Animal Farm\"][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T01:48:00.500339Z",
     "start_time": "2017-08-25T01:47:58.549705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scattertext as st\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T01:54:48.028464Z",
     "start_time": "2017-08-25T01:54:43.171419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That Thou Art Mindful of Him</td>\n",
       "      <td>In this story, Asimov describesS.\\nRobots' att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!Hero</td>\n",
       "      <td>HERO is a rock opera modernizing Jesus's last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&amp;quot;A&amp;quot; Is for Alibi</td>\n",
       "      <td>\"A\" Is for Alibi features Kinsey Millhone, 32,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&amp;quot;Master Harold&amp;quot;and the Boys</td>\n",
       "      <td>The play recounts the long, rainy afternoon th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;quot;Pimpernel&amp;quot; Smith</td>\n",
       "      <td>Eccentric Cambridge archaeologist Horatio Smit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "0           That Thou Art Mindful of Him   \n",
       "1                                  !Hero   \n",
       "2             &quot;A&quot; Is for Alibi   \n",
       "3  &quot;Master Harold&quot;and the Boys   \n",
       "4            &quot;Pimpernel&quot; Smith   \n",
       "\n",
       "                                                plot  \n",
       "0  In this story, Asimov describesS.\\nRobots' att...  \n",
       "1  HERO is a rock opera modernizing Jesus's last ...  \n",
       "2  \"A\" Is for Alibi features Kinsey Millhone, 32,...  \n",
       "3  The play recounts the long, rainy afternoon th...  \n",
       "4  Eccentric Cambridge archaeologist Horatio Smit...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(plot_dict, index=['plot']).transpose().reset_index()\n",
    "df.columns = ['title', 'plot']\n",
    "\n",
    "# print(len(df))\n",
    "# df.replace('', np.nan, inplace=True)\n",
    "# print(len(df))\n",
    "\n",
    "#df.drop(df[len(df['plot'])<50])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T01:55:16.712113Z",
     "start_time": "2017-08-25T01:55:02.292774Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from scattertext import SampleCorpora, word_similarity_explorer_gensim, Word2VecFromParsedCorpus\n",
    "from scattertext.CorpusFromParsedDocuments import CorpusFromParsedDocuments\n",
    "nlp = spacy.en.English()\n",
    "df['parsed'] = df['plot'].apply(nlp)\n",
    "corpus = CorpusFromParsedDocuments(convention_df, category_col='category', parsed_col='parsed').build()\n",
    "model = word2vec.Word2Vec(size=300,\n",
    "                          alpha=0.025,\n",
    "                          window=5,\n",
    "                          min_count=5,\n",
    "                          max_vocab_size=None,\n",
    "                          sample=0,\n",
    "                          seed=1,\n",
    "                          workers=1,\n",
    "                          min_alpha=0.0001,\n",
    "                          sg=1,\n",
    "                          hs=1,\n",
    "                          negative=0,\n",
    "                          cbow_mean=0,\n",
    "                          iter=1,\n",
    "                          null_word=0,\n",
    "                          trim_rule=None,\n",
    "                          sorted_vocab=1)\n",
    "html = word_similarity_explorer_gensim(corpus,\n",
    "                                       category='democrat',\n",
    "                                       category_name='Democratic',\n",
    "                                       not_category_name='Republican',\n",
    "                                       target_term='jobs',\n",
    "                                       minimum_term_frequency=5,\n",
    "                                       pmi_threshold_coefficient=4,\n",
    "                                       width_in_pixels=1000,\n",
    "                                       metadata=convention_df['speaker'],\n",
    "                                       word2vec=Word2VecFromParsedCorpus(corpus, model).train(),\n",
    "                                       max_p_val=0.05,\n",
    "                                       save_svg_button=True)\n",
    "open('./demo_gensim_similarity.html', 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T02:14:14.620659Z",
     "start_time": "2017-08-25T02:14:14.604943Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "file_text = \"/home/ubuntu/raw_data/plots\"\n",
    "\n",
    "# The txt file is opened and tokenized\n",
    "text_tokens = nltk.word_tokenize(file_text)\n",
    "\n",
    "# Named-entity recognition\n",
    "corp_tag = nltk.pos_tag(text_tokens)\n",
    "\n",
    "corp_chunk = nltk.ne_chunk(corp_tag)\n",
    "\n",
    "proper = []\n",
    "for token in corp_chunk: \n",
    "    if hasattr(token, 'label') and token.label() == \"PERSON\":\n",
    "            proper.append(\" \".join(c[0] for c in token.leaves()))\n",
    "\n",
    "# Find the most common proper nouns \n",
    "# (in our case, only the first word was kept to eliminate duplicates \n",
    "# like first-name last-name, and last-name)           \n",
    "top_30 = Counter(proper).most_common(30)  \n",
    "\n",
    "# Find similar words \n",
    "text = nltk.text.ContextIndex([word for word in text_tokens])\n",
    "\n",
    "all_words = {}\n",
    "for word in text.tokens():\n",
    "    for similar_words in text.similar_words() :\n",
    "        all_words[word] = word\n",
    "        for similar_word in similar_words:\n",
    "            all_words[similar_word] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T02:14:30.592182Z",
     "start_time": "2017-08-25T02:14:30.588488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
